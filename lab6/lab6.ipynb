{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Labs\\NeuralNetworkLabs\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import models, layers\n",
    "from keras.models import Model, model_from_json, Sequential\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, SeparableConv2D, UpSampling2D, BatchNormalization, Input, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_flow(inputs) :\n",
    "\n",
    "    x = Conv2D(32, 3, strides = 2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    previous_block_activation = x\n",
    "\n",
    "    for size in [128, 256, 728] :\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "        residual = Conv2D(size, 1, strides=2, padding='same')(previous_block_activation)\n",
    "\n",
    "        x = keras.layers.Add()([x, residual])\n",
    "        previous_block_activation = x\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_flow(x, num_blocks=8) :\n",
    "\n",
    "    previous_block_activation = x\n",
    "\n",
    "    for _ in range(num_blocks) :\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = keras.layers.Add()([x, previous_block_activation])\n",
    "        previous_block_activation = x\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_flow(x) :\n",
    "\n",
    "    previous_block_activation = x\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(1024, 3, padding='same')(x) \n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    residual = Conv2D(1024, 1, strides=2, padding='same')(previous_block_activation)\n",
    "    x = keras.layers.Add()([x, residual])\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(1024, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Labs\\NeuralNetworkLabs\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Labs\\NeuralNetworkLabs\\.venv\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(299, 299, 3))\n",
    "outputs = exit_flow(middle_flow(entry_flow(inputs)))\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 299, 299, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 150, 150, 32)         896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 150, 150, 32)         128       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 150, 150, 32)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 150, 150, 64)         18496     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 150, 150, 64)         256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 150, 150, 64)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 150, 150, 64)         0         ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " separable_conv2d (Separabl  (None, 150, 150, 128)        8896      ['activation_2[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 150, 150, 128)        512       ['separable_conv2d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 150, 150, 128)        0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (Separa  (None, 150, 150, 128)        17664     ['activation_3[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 150, 150, 128)        512       ['separable_conv2d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 75, 75, 128)          0         ['batch_normalization_3[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 75, 75, 128)          8320      ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 75, 75, 128)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 75, 75, 128)          0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (Separa  (None, 75, 75, 256)          34176     ['activation_4[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 75, 75, 256)          1024      ['separable_conv2d_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 75, 75, 256)          0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (Separa  (None, 75, 75, 256)          68096     ['activation_5[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 75, 75, 256)          1024      ['separable_conv2d_3[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 38, 38, 256)          0         ['batch_normalization_5[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 38, 38, 256)          33024     ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 38, 38, 256)          0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 38, 38, 256)          0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (Separa  (None, 38, 38, 728)          189400    ['activation_6[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 38, 38, 728)          2912      ['separable_conv2d_4[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 38, 38, 728)          0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (Separa  (None, 38, 38, 728)          537264    ['activation_7[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 38, 38, 728)          2912      ['separable_conv2d_5[0][0]']  \n",
      " chNormalization)                                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 19, 19, 728)          0         ['batch_normalization_7[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 19, 19, 728)          187096    ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 19, 19, 728)          0         ['max_pooling2d_2[0][0]',     \n",
      "                                                                     'conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 19, 19, 728)          0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (Separa  (None, 19, 19, 728)          537264    ['activation_8[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 19, 19, 728)          2912      ['separable_conv2d_6[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 19, 19, 728)          0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_7 (Separa  (None, 19, 19, 728)          537264    ['activation_9[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 19, 19, 728)          2912      ['separable_conv2d_7[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_8 (Separa  (None, 19, 19, 728)          537264    ['activation_10[0][0]']       \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_8[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 19, 19, 728)          0         ['batch_normalization_10[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 19, 19, 728)          0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_9 (Separa  (None, 19, 19, 728)          537264    ['activation_11[0][0]']       \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_9[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_10 (Separ  (None, 19, 19, 728)          537264    ['activation_12[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_10[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_11 (Separ  (None, 19, 19, 728)          537264    ['activation_13[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_11[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 19, 19, 728)          0         ['batch_normalization_13[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 19, 19, 728)          0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_12 (Separ  (None, 19, 19, 728)          537264    ['activation_14[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_12[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_13 (Separ  (None, 19, 19, 728)          537264    ['activation_15[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_13[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_14 (Separ  (None, 19, 19, 728)          537264    ['activation_16[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_14[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 19, 19, 728)          0         ['batch_normalization_16[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 19, 19, 728)          0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_15 (Separ  (None, 19, 19, 728)          537264    ['activation_17[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_15[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_16 (Separ  (None, 19, 19, 728)          537264    ['activation_18[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_16[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_17 (Separ  (None, 19, 19, 728)          537264    ['activation_19[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_17[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 19, 19, 728)          0         ['batch_normalization_19[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_5[0][0]']               \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 19, 19, 728)          0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_18 (Separ  (None, 19, 19, 728)          537264    ['activation_20[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_18[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_19 (Separ  (None, 19, 19, 728)          537264    ['activation_21[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_19[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_20 (Separ  (None, 19, 19, 728)          537264    ['activation_22[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_20[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 19, 19, 728)          0         ['batch_normalization_22[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_6[0][0]']               \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 19, 19, 728)          0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_21 (Separ  (None, 19, 19, 728)          537264    ['activation_23[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_21[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_22 (Separ  (None, 19, 19, 728)          537264    ['activation_24[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_22[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_23 (Separ  (None, 19, 19, 728)          537264    ['activation_25[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_23[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 19, 19, 728)          0         ['batch_normalization_25[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_7[0][0]']               \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 19, 19, 728)          0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_24 (Separ  (None, 19, 19, 728)          537264    ['activation_26[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_24[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_25 (Separ  (None, 19, 19, 728)          537264    ['activation_27[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_25[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_26 (Separ  (None, 19, 19, 728)          537264    ['activation_28[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_26[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 19, 19, 728)          0         ['batch_normalization_28[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_8[0][0]']               \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 19, 19, 728)          0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_27 (Separ  (None, 19, 19, 728)          537264    ['activation_29[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_27[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_28 (Separ  (None, 19, 19, 728)          537264    ['activation_30[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_28[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_29 (Separ  (None, 19, 19, 728)          537264    ['activation_31[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_29[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 19, 19, 728)          0         ['batch_normalization_31[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_9[0][0]']               \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, 19, 19, 728)          0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " separable_conv2d_30 (Separ  (None, 19, 19, 728)          537264    ['activation_32[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 19, 19, 728)          2912      ['separable_conv2d_30[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, 19, 19, 728)          0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_31 (Separ  (None, 19, 19, 1024)         753048    ['activation_33[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 19, 19, 1024)         4096      ['separable_conv2d_31[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 10, 10, 1024)         0         ['batch_normalization_33[0][0]\n",
      " g2D)                                                               ']                            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 10, 10, 1024)         746496    ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 10, 10, 1024)         0         ['max_pooling2d_3[0][0]',     \n",
      "                                                                     'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, 10, 10, 1024)         0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " separable_conv2d_32 (Separ  (None, 10, 10, 728)          755416    ['activation_34[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 10, 10, 728)          2912      ['separable_conv2d_32[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, 10, 10, 728)          0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_33 (Separ  (None, 10, 10, 1024)         753048    ['activation_35[0][0]']       \n",
      " ableConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 10, 10, 1024)         4096      ['separable_conv2d_33[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 1024)                 0         ['batch_normalization_35[0][0]\n",
      " GlobalAveragePooling2D)                                            ']                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    1025      ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17637145 (67.28 MB)\n",
      "Trainable params: 17590553 (67.10 MB)\n",
      "Non-trainable params: 46592 (182.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 632 images belonging to 2 classes.\n",
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2  \n",
    "\n",
    "\n",
    "# training parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "image_height = 299\n",
    "image_width = 299\n",
    "\n",
    "# Шляхи до директорій для тренування та валідації для кожного класу\n",
    "train_dir = \"./brandDataset/train\"\n",
    "valid_dir = \"./brandDataset/validation\"\n",
    "\n",
    "# Зазначення назв класів\n",
    "class_names = ['apple', 'others']\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                  rescale=1./255,\n",
    "                  rotation_range=10,\n",
    "                  width_shift_range=0.1,\n",
    "                  height_shift_range=0.1,\n",
    "                  shear_range=0.1,\n",
    "                  zoom_range=0.1)\n",
    "\n",
    "# Зміна параметрів генераторів для відповідних кількостей класів\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(image_height, image_width),\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"binary\",  \n",
    "                                                    classes=class_names)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
    "                                                    target_size=(image_height, image_width),\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    seed=7,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"binary\",  \n",
    "                                                    classes=class_names)\n",
    "\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Labs\\NeuralNetworkLabs\\.venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Labs\\NeuralNetworkLabs\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 1/19 [>.............................] - ETA: 11:27 - loss: 0.6818 - accuracy: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Labs\\NeuralNetworkLabs\\.venv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 265s 13s/step - loss: 0.8791 - accuracy: 0.5417 - val_loss: 0.7167 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 239s 13s/step - loss: 0.6916 - accuracy: 0.5983 - val_loss: 0.7274 - val_accuracy: 0.5104\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.7076 - accuracy: 0.6450 - val_loss: 0.7261 - val_accuracy: 0.5208\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 240s 13s/step - loss: 0.6300 - accuracy: 0.6467 - val_loss: 0.7307 - val_accuracy: 0.5104\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.6407 - accuracy: 0.6500 - val_loss: 0.7581 - val_accuracy: 0.4479\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.6087 - accuracy: 0.6583 - val_loss: 0.7361 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 236s 12s/step - loss: 0.6417 - accuracy: 0.6217 - val_loss: 0.7392 - val_accuracy: 0.4896\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.6320 - accuracy: 0.6400 - val_loss: 0.7285 - val_accuracy: 0.4896\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 236s 12s/step - loss: 0.6031 - accuracy: 0.6733 - val_loss: 0.7086 - val_accuracy: 0.5417\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 238s 13s/step - loss: 0.6305 - accuracy: 0.6617 - val_loss: 0.7349 - val_accuracy: 0.4896\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 241s 13s/step - loss: 0.6106 - accuracy: 0.6650 - val_loss: 0.7355 - val_accuracy: 0.5104\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.6238 - accuracy: 0.6633 - val_loss: 0.7193 - val_accuracy: 0.5208\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.5747 - accuracy: 0.6850 - val_loss: 0.7288 - val_accuracy: 0.4896\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 238s 13s/step - loss: 0.5584 - accuracy: 0.7083 - val_loss: 0.7739 - val_accuracy: 0.4583\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 246s 13s/step - loss: 0.5574 - accuracy: 0.7100 - val_loss: 0.7302 - val_accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.5457 - accuracy: 0.7253 - val_loss: 0.7407 - val_accuracy: 0.4688\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.5448 - accuracy: 0.7183 - val_loss: 0.6934 - val_accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.5105 - accuracy: 0.7500 - val_loss: 0.6912 - val_accuracy: 0.5208\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.5505 - accuracy: 0.7283 - val_loss: 0.7628 - val_accuracy: 0.4896\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.5747 - accuracy: 0.7100 - val_loss: 0.6842 - val_accuracy: 0.5625\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.5312 - accuracy: 0.7333 - val_loss: 0.6918 - val_accuracy: 0.5521\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.5377 - accuracy: 0.7220 - val_loss: 0.6905 - val_accuracy: 0.5521\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 236s 12s/step - loss: 0.5402 - accuracy: 0.7200 - val_loss: 0.6927 - val_accuracy: 0.5625\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.5102 - accuracy: 0.7700 - val_loss: 0.7918 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.4515 - accuracy: 0.7717 - val_loss: 0.6642 - val_accuracy: 0.5938\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.4524 - accuracy: 0.7917 - val_loss: 0.5849 - val_accuracy: 0.6875\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.4727 - accuracy: 0.7833 - val_loss: 0.8928 - val_accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 240s 13s/step - loss: 0.4261 - accuracy: 0.7783 - val_loss: 0.6647 - val_accuracy: 0.6458\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.4874 - accuracy: 0.7717 - val_loss: 0.7611 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 242s 13s/step - loss: 0.4169 - accuracy: 0.7917 - val_loss: 0.6091 - val_accuracy: 0.6875\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 251s 13s/step - loss: 0.4627 - accuracy: 0.7833 - val_loss: 0.6145 - val_accuracy: 0.7083\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 246s 13s/step - loss: 0.4253 - accuracy: 0.8117 - val_loss: 0.7928 - val_accuracy: 0.6458\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 238s 12s/step - loss: 0.4054 - accuracy: 0.7900 - val_loss: 1.1448 - val_accuracy: 0.6771\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 240s 13s/step - loss: 0.4231 - accuracy: 0.8033 - val_loss: 0.6583 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 238s 13s/step - loss: 0.4232 - accuracy: 0.8067 - val_loss: 0.8013 - val_accuracy: 0.7292\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 236s 12s/step - loss: 0.3448 - accuracy: 0.8533 - val_loss: 0.6521 - val_accuracy: 0.6979\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 239s 13s/step - loss: 0.3804 - accuracy: 0.8517 - val_loss: 1.4314 - val_accuracy: 0.6146\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 236s 12s/step - loss: 0.3547 - accuracy: 0.8367 - val_loss: 1.2777 - val_accuracy: 0.6354\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 238s 13s/step - loss: 0.3016 - accuracy: 0.8667 - val_loss: 1.4644 - val_accuracy: 0.6146\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.3099 - accuracy: 0.8783 - val_loss: 0.7566 - val_accuracy: 0.7292\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 244s 13s/step - loss: 0.3000 - accuracy: 0.8817 - val_loss: 1.4349 - val_accuracy: 0.6458\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 250s 13s/step - loss: 0.2856 - accuracy: 0.8883 - val_loss: 5.9694 - val_accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 243s 13s/step - loss: 0.2702 - accuracy: 0.8967 - val_loss: 11.1635 - val_accuracy: 0.5417\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.2644 - accuracy: 0.8800 - val_loss: 7.4717 - val_accuracy: 0.4896\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.2893 - accuracy: 0.8633 - val_loss: 7.8525 - val_accuracy: 0.5208\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.2459 - accuracy: 0.8933 - val_loss: 3.1238 - val_accuracy: 0.6562\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.1997 - accuracy: 0.9183 - val_loss: 1.5169 - val_accuracy: 0.7188\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.2540 - accuracy: 0.9017 - val_loss: 2.6271 - val_accuracy: 0.6875\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.2293 - accuracy: 0.9183 - val_loss: 8.7160 - val_accuracy: 0.6042\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.2449 - accuracy: 0.9083 - val_loss: 2.6275 - val_accuracy: 0.7917\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.2040 - accuracy: 0.9217 - val_loss: 1.5494 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.1952 - accuracy: 0.9250 - val_loss: 1.4929 - val_accuracy: 0.7083\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.1533 - accuracy: 0.9383 - val_loss: 0.9915 - val_accuracy: 0.7708\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.1312 - accuracy: 0.9500 - val_loss: 1.3873 - val_accuracy: 0.7396\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.1581 - accuracy: 0.9383 - val_loss: 1.1337 - val_accuracy: 0.7708\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.1300 - accuracy: 0.9533 - val_loss: 1.3093 - val_accuracy: 0.7812\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.1383 - accuracy: 0.9533 - val_loss: 0.6211 - val_accuracy: 0.8125\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.1724 - accuracy: 0.9367 - val_loss: 2.1199 - val_accuracy: 0.7292\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 238s 13s/step - loss: 0.1493 - accuracy: 0.9507 - val_loss: 2.1696 - val_accuracy: 0.6562\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.1732 - accuracy: 0.9333 - val_loss: 2.2000 - val_accuracy: 0.6875\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.1086 - accuracy: 0.9600 - val_loss: 0.7634 - val_accuracy: 0.7604\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.1473 - accuracy: 0.9400 - val_loss: 1.3188 - val_accuracy: 0.7083\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 229s 12s/step - loss: 0.1004 - accuracy: 0.9650 - val_loss: 1.3398 - val_accuracy: 0.7292\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.0559 - accuracy: 0.9783 - val_loss: 1.0222 - val_accuracy: 0.6875\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0789 - accuracy: 0.9750 - val_loss: 1.8241 - val_accuracy: 0.7083\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 229s 12s/step - loss: 0.1956 - accuracy: 0.9250 - val_loss: 1.5505 - val_accuracy: 0.7604\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.2561 - accuracy: 0.8967 - val_loss: 1.7668 - val_accuracy: 0.6562\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.1470 - accuracy: 0.9417 - val_loss: 1.1471 - val_accuracy: 0.8125\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0992 - accuracy: 0.9717 - val_loss: 1.1960 - val_accuracy: 0.7708\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0958 - accuracy: 0.9617 - val_loss: 1.0342 - val_accuracy: 0.7917\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 229s 12s/step - loss: 0.0987 - accuracy: 0.9517 - val_loss: 1.2267 - val_accuracy: 0.7396\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 1.5637 - val_accuracy: 0.7708\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 237s 12s/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 1.6044 - val_accuracy: 0.7396\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.1017 - accuracy: 0.9517 - val_loss: 1.2937 - val_accuracy: 0.7083\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 229s 12s/step - loss: 0.0781 - accuracy: 0.9700 - val_loss: 1.2418 - val_accuracy: 0.6771\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 236s 12s/step - loss: 0.1135 - accuracy: 0.9583 - val_loss: 3.9477 - val_accuracy: 0.5521\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.1298 - accuracy: 0.9533 - val_loss: 0.8822 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.0697 - accuracy: 0.9767 - val_loss: 0.8575 - val_accuracy: 0.7708\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0737 - accuracy: 0.9817 - val_loss: 1.1143 - val_accuracy: 0.7708\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0633 - accuracy: 0.9867 - val_loss: 1.0808 - val_accuracy: 0.8021\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0630 - accuracy: 0.9767 - val_loss: 1.0701 - val_accuracy: 0.7812\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0776 - accuracy: 0.9717 - val_loss: 1.3744 - val_accuracy: 0.7708\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.0570 - accuracy: 0.9800 - val_loss: 0.5973 - val_accuracy: 0.8438\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0939 - accuracy: 0.9700 - val_loss: 1.0259 - val_accuracy: 0.7708\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0679 - accuracy: 0.9817 - val_loss: 0.7684 - val_accuracy: 0.8125\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 0.7062 - val_accuracy: 0.7917\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.0506 - accuracy: 0.9836 - val_loss: 0.5140 - val_accuracy: 0.8646\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.0385 - accuracy: 0.9800 - val_loss: 1.4864 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0497 - accuracy: 0.9817 - val_loss: 0.7142 - val_accuracy: 0.7917\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.9116 - val_accuracy: 0.7812\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0381 - accuracy: 0.9833 - val_loss: 0.8488 - val_accuracy: 0.8021\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 243s 13s/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 1.0168 - val_accuracy: 0.8021\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0950 - accuracy: 0.9683 - val_loss: 1.0441 - val_accuracy: 0.7708\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 233s 12s/step - loss: 0.0708 - accuracy: 0.9700 - val_loss: 0.7799 - val_accuracy: 0.8542\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0440 - accuracy: 0.9817 - val_loss: 0.4811 - val_accuracy: 0.8646\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.5982 - val_accuracy: 0.8542\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.0393 - accuracy: 0.9850 - val_loss: 0.5244 - val_accuracy: 0.8438\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0931 - accuracy: 0.9633 - val_loss: 3.0783 - val_accuracy: 0.6458\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0382 - accuracy: 0.9817 - val_loss: 1.3424 - val_accuracy: 0.8021\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0383 - accuracy: 0.9833 - val_loss: 0.8596 - val_accuracy: 0.8229\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=train_num // BATCH_SIZE,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_num // BATCH_SIZE,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Labs\\NeuralNetworkLabs\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Збереження моделі\n",
    "model.save('logo_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predictions: [[0.49526945]]\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Predictions: [[0.5044345]]\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Predictions: [[0.5041316]]\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.5040687]]\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.50455034]]\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.5046581]]\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.50456876]]\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Predictions: [[0.50516516]]\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Predictions: [[0.50524485]]\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.5095565]]\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predictions: [[0.50699633]]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Predictions: [[0.5107432]]\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Predictions: [[0.51112205]]\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Predictions: [[0.50713867]]\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predictions: [[0.5070341]]\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.50694823]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.5108043]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.51095486]]\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.5050111]]\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.39283457]]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Predictions: [[0.09614242]]\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.3033849]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.27427316]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.2152066]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.19600525]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.17986245]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.57966805]]\n",
      "Logo detected at time: 0.9 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.3074795]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.2939617]]\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Predictions: [[0.37711832]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.35790563]]\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.3058983]]\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Predictions: [[0.36389622]]\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.25476617]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.37363836]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.3201906]]\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Predictions: [[0.20162757]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.19197626]]\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.39745665]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.08582629]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.28686854]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.24218324]]\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.37791055]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.38043612]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.5882504]]\n",
      "Logo detected at time: 1.5 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.4575631]]\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.43901753]]\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.3274048]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.35937092]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.46339872]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.39695066]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.3547961]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.32984692]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.2843954]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.25295845]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.25035638]]\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.23914215]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.21779041]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.22577068]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.20659496]]\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.19066496]]\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Predictions: [[0.18491617]]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.18353957]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.17428182]]\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.16709596]]\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.16153093]]\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.15779623]]\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.15316154]]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.15261205]]\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.15254797]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.14761163]]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.14605138]]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.14775111]]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.14771281]]\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.14704606]]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.14453325]]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.14523959]]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Predictions: [[0.14527161]]\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.14471525]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.14458853]]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.14511043]]\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.14624654]]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.1457544]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.14568065]]\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.14576001]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.14581458]]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.14532092]]\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.1442377]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.14473048]]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Predictions: [[0.14479753]]\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.1443948]]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.1443107]]\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Predictions: [[0.14481886]]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.14508556]]\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.14453143]]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9999913]]\n",
      "Logo detected at time: 3.2 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.99999124]]\n",
      "Logo detected at time: 3.2333333333333334 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.99999124]]\n",
      "Logo detected at time: 3.2666666666666666 seconds\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Predictions: [[0.9999913]]\n",
      "Logo detected at time: 3.3 seconds\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Predictions: [[0.99999106]]\n",
      "Logo detected at time: 3.3333333333333335 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.3666666666666667 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 3.4 seconds\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Predictions: [[0.999991]]\n",
      "Logo detected at time: 3.433333333333333 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999106]]\n",
      "Logo detected at time: 3.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.999991]]\n",
      "Logo detected at time: 3.5 seconds\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predictions: [[0.9999912]]\n",
      "Logo detected at time: 3.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Predictions: [[0.99999124]]\n",
      "Logo detected at time: 3.566666666666667 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.99999124]]\n",
      "Logo detected at time: 3.6 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 3.6333333333333333 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 3.6666666666666665 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.7 seconds\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predictions: [[0.999991]]\n",
      "Logo detected at time: 3.7333333333333334 seconds\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.7666666666666666 seconds\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.8 seconds\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.8333333333333335 seconds\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.8666666666666667 seconds\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 3.9 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.933333333333333 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 3.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.999991]]\n",
      "Logo detected at time: 4.0 seconds\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Predictions: [[0.999991]]\n",
      "Logo detected at time: 4.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.999991]]\n",
      "Logo detected at time: 4.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.999991]]\n",
      "Logo detected at time: 4.1 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 4.133333333333334 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 4.166666666666667 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999094]]\n",
      "Logo detected at time: 4.2 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.9999911]]\n",
      "Logo detected at time: 4.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9999911]]\n",
      "Logo detected at time: 4.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9999911]]\n",
      "Logo detected at time: 4.3 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 4.333333333333333 seconds\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.366666666666666 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 4.4 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 4.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 4.5 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 4.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.6 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 4.633333333333334 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 4.666666666666667 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 4.7 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.8 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 4.833333333333333 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.866666666666666 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.9999909]]\n",
      "Logo detected at time: 4.9 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 4.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.0 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.1 seconds\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.133333333333334 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.166666666666667 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.2 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.3 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.333333333333333 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.366666666666666 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.4 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.5 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.6 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.633333333333334 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.666666666666667 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.7 seconds\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 5.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.8 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.833333333333333 seconds\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.866666666666666 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 5.9 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 5.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 5.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.0 seconds\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.1 seconds\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.133333333333334 seconds\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.166666666666667 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.2 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.3 seconds\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 6.333333333333333 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 6.366666666666666 seconds\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 6.4 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 6.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 6.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.5 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.6 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.633333333333334 seconds\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.666666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.7 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.8 seconds\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 6.833333333333333 seconds\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.866666666666666 seconds\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.9 seconds\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 6.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.0 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.1 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 7.133333333333334 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.9999908]]\n",
      "Logo detected at time: 7.166666666666667 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.2 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.3 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.333333333333333 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.366666666666666 seconds\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.4 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.5 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.6 seconds\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.633333333333334 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.666666666666667 seconds\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.7 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.8 seconds\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.833333333333333 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.866666666666666 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 7.9 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 7.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.9999907]]\n",
      "Logo detected at time: 8.0 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 8.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 8.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.99999064]]\n",
      "Logo detected at time: 8.1 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 8.133333333333333 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.99999076]]\n",
      "Logo detected at time: 8.166666666666666 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9871511]]\n",
      "Logo detected at time: 8.2 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.98709047]]\n",
      "Logo detected at time: 8.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.9871062]]\n",
      "Logo detected at time: 8.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.98711056]]\n",
      "Logo detected at time: 8.3 seconds\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.9871173]]\n",
      "Logo detected at time: 8.333333333333334 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.98658204]]\n",
      "Logo detected at time: 8.366666666666667 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.9866045]]\n",
      "Logo detected at time: 8.4 seconds\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.986473]]\n",
      "Logo detected at time: 8.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.986457]]\n",
      "Logo detected at time: 8.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9865048]]\n",
      "Logo detected at time: 8.5 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9867109]]\n",
      "Logo detected at time: 8.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.98669094]]\n",
      "Logo detected at time: 8.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.9866771]]\n",
      "Logo detected at time: 8.6 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.98659825]]\n",
      "Logo detected at time: 8.633333333333333 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.9865959]]\n",
      "Logo detected at time: 8.666666666666666 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.9865899]]\n",
      "Logo detected at time: 8.7 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.98662657]]\n",
      "Logo detected at time: 8.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.98664373]]\n",
      "Logo detected at time: 8.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.98664385]]\n",
      "Logo detected at time: 8.8 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.98658144]]\n",
      "Logo detected at time: 8.833333333333334 seconds\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Predictions: [[0.986574]]\n",
      "Logo detected at time: 8.866666666666667 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9865892]]\n",
      "Logo detected at time: 8.9 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.98664594]]\n",
      "Logo detected at time: 8.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9866379]]\n",
      "Logo detected at time: 8.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.9866282]]\n",
      "Logo detected at time: 9.0 seconds\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Predictions: [[0.98658097]]\n",
      "Logo detected at time: 9.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.98657906]]\n",
      "Logo detected at time: 9.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9865732]]\n",
      "Logo detected at time: 9.1 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.98662466]]\n",
      "Logo detected at time: 9.133333333333333 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.98664236]]\n",
      "Logo detected at time: 9.166666666666666 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.98664254]]\n",
      "Logo detected at time: 9.2 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.9865697]]\n",
      "Logo detected at time: 9.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.98656213]]\n",
      "Logo detected at time: 9.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Predictions: [[0.98657745]]\n",
      "Logo detected at time: 9.3 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.98662615]]\n",
      "Logo detected at time: 9.333333333333334 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9866178]]\n",
      "Logo detected at time: 9.366666666666667 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.98660874]]\n",
      "Logo detected at time: 9.4 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.98657453]]\n",
      "Logo detected at time: 9.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9865732]]\n",
      "Logo detected at time: 9.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9865664]]\n",
      "Logo detected at time: 9.5 seconds\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Predictions: [[0.98656315]]\n",
      "Logo detected at time: 9.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.98658246]]\n",
      "Logo detected at time: 9.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.9865815]]\n",
      "Logo detected at time: 9.6 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9865525]]\n",
      "Logo detected at time: 9.633333333333333 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9865442]]\n",
      "Logo detected at time: 9.666666666666666 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.9865583]]\n",
      "Logo detected at time: 9.7 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.98658836]]\n",
      "Logo detected at time: 9.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Predictions: [[0.9865802]]\n",
      "Logo detected at time: 9.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9865701]]\n",
      "Logo detected at time: 9.8 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.9865583]]\n",
      "Logo detected at time: 9.833333333333334 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.9865576]]\n",
      "Logo detected at time: 9.866666666666667 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.9865525]]\n",
      "Logo detected at time: 9.9 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.9865701]]\n",
      "Logo detected at time: 9.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.986588]]\n",
      "Logo detected at time: 9.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.98658836]]\n",
      "Logo detected at time: 10.0 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.98661774]]\n",
      "Logo detected at time: 10.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.98660964]]\n",
      "Logo detected at time: 10.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.986624]]\n",
      "Logo detected at time: 10.1 seconds\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predictions: [[0.98664963]]\n",
      "Logo detected at time: 10.133333333333333 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.98664045]]\n",
      "Logo detected at time: 10.166666666666666 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.9866327]]\n",
      "Logo detected at time: 10.2 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.9866173]]\n",
      "Logo detected at time: 10.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.9866155]]\n",
      "Logo detected at time: 10.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Predictions: [[0.98661214]]\n",
      "Logo detected at time: 10.3 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.9866754]]\n",
      "Logo detected at time: 10.333333333333334 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.986693]]\n",
      "Logo detected at time: 10.366666666666667 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.98669904]]\n",
      "Logo detected at time: 10.4 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.98660904]]\n",
      "Logo detected at time: 10.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.9866028]]\n",
      "Logo detected at time: 10.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.98661643]]\n",
      "Logo detected at time: 10.5 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.98670226]]\n",
      "Logo detected at time: 10.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.9866968]]\n",
      "Logo detected at time: 10.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9866907]]\n",
      "Logo detected at time: 10.6 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.98662645]]\n",
      "Logo detected at time: 10.633333333333333 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.9866217]]\n",
      "Logo detected at time: 10.666666666666666 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9866168]]\n",
      "Logo detected at time: 10.7 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9866709]]\n",
      "Logo detected at time: 10.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.98668873]]\n",
      "Logo detected at time: 10.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.9866871]]\n",
      "Logo detected at time: 10.8 seconds\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Predictions: [[0.98662186]]\n",
      "Logo detected at time: 10.833333333333334 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.98661655]]\n",
      "Logo detected at time: 10.866666666666667 seconds\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Predictions: [[0.98662764]]\n",
      "Logo detected at time: 10.9 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.9866952]]\n",
      "Logo detected at time: 10.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.98668706]]\n",
      "Logo detected at time: 10.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Predictions: [[0.9866797]]\n",
      "Logo detected at time: 11.0 seconds\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Predictions: [[0.98662454]]\n",
      "Logo detected at time: 11.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.9866212]]\n",
      "Logo detected at time: 11.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.9866161]]\n",
      "Logo detected at time: 11.1 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.9866561]]\n",
      "Logo detected at time: 11.133333333333333 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.9866783]]\n",
      "Logo detected at time: 11.166666666666666 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.98667175]]\n",
      "Logo detected at time: 11.2 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.98662305]]\n",
      "Logo detected at time: 11.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.80704796]]\n",
      "Logo detected at time: 11.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.8068217]]\n",
      "Logo detected at time: 11.3 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.8080388]]\n",
      "Logo detected at time: 11.333333333333334 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.80829537]]\n",
      "Logo detected at time: 11.366666666666667 seconds\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predictions: [[0.80782473]]\n",
      "Logo detected at time: 11.4 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.8085978]]\n",
      "Logo detected at time: 11.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predictions: [[0.8089816]]\n",
      "Logo detected at time: 11.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.80716914]]\n",
      "Logo detected at time: 11.5 seconds\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Predictions: [[0.8062654]]\n",
      "Logo detected at time: 11.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.8059451]]\n",
      "Logo detected at time: 11.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.8057583]]\n",
      "Logo detected at time: 11.6 seconds\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predictions: [[0.80631304]]\n",
      "Logo detected at time: 11.633333333333333 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.8063282]]\n",
      "Logo detected at time: 11.666666666666666 seconds\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predictions: [[0.8062739]]\n",
      "Logo detected at time: 11.7 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.80599916]]\n",
      "Logo detected at time: 11.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.8060659]]\n",
      "Logo detected at time: 11.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Predictions: [[0.8060713]]\n",
      "Logo detected at time: 11.8 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.8063445]]\n",
      "Logo detected at time: 11.833333333333334 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.8063258]]\n",
      "Logo detected at time: 11.866666666666667 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.8063952]]\n",
      "Logo detected at time: 11.9 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.80522513]]\n",
      "Logo detected at time: 11.933333333333334 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.80516833]]\n",
      "Logo detected at time: 11.966666666666667 seconds\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predictions: [[0.8051567]]\n",
      "Logo detected at time: 12.0 seconds\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Predictions: [[0.806251]]\n",
      "Logo detected at time: 12.033333333333333 seconds\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Predictions: [[0.8062462]]\n",
      "Logo detected at time: 12.066666666666666 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.8062019]]\n",
      "Logo detected at time: 12.1 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.80651194]]\n",
      "Logo detected at time: 12.133333333333333 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.8065736]]\n",
      "Logo detected at time: 12.166666666666666 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.80656976]]\n",
      "Logo detected at time: 12.2 seconds\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Predictions: [[0.8065243]]\n",
      "Logo detected at time: 12.233333333333333 seconds\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "Predictions: [[0.8065323]]\n",
      "Logo detected at time: 12.266666666666667 seconds\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Predictions: [[0.8065577]]\n",
      "Logo detected at time: 12.3 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.80782276]]\n",
      "Logo detected at time: 12.333333333333334 seconds\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predictions: [[0.8099521]]\n",
      "Logo detected at time: 12.366666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.8099424]]\n",
      "Logo detected at time: 12.4 seconds\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Predictions: [[0.80837804]]\n",
      "Logo detected at time: 12.433333333333334 seconds\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Predictions: [[0.8085948]]\n",
      "Logo detected at time: 12.466666666666667 seconds\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Predictions: [[0.8083831]]\n",
      "Logo detected at time: 12.5 seconds\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Predictions: [[0.8092847]]\n",
      "Logo detected at time: 12.533333333333333 seconds\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Predictions: [[0.8092152]]\n",
      "Logo detected at time: 12.566666666666666 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.8094922]]\n",
      "Logo detected at time: 12.6 seconds\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Predictions: [[0.80844975]]\n",
      "Logo detected at time: 12.633333333333333 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.80824065]]\n",
      "Logo detected at time: 12.666666666666666 seconds\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Predictions: [[0.8083664]]\n",
      "Logo detected at time: 12.7 seconds\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Predictions: [[0.8084863]]\n",
      "Logo detected at time: 12.733333333333333 seconds\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predictions: [[0.8079536]]\n",
      "Logo detected at time: 12.766666666666667 seconds\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Predictions: [[0.80827713]]\n",
      "Logo detected at time: 12.8 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Завантаження навченої моделі\n",
    "model = load_model('logo_detection_model.h5')\n",
    "\n",
    "# Відкриття відеофайлу\n",
    "video_capture = cv2.VideoCapture('my_video.mp4')\n",
    "img_size = (299, 299)\n",
    "\n",
    "# Визначення властивостей відео\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Цикл обробки кадрів\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Переведення зображення до формату, який можна використовувати для моделі\n",
    "    input_image = cv2.resize(frame, img_size)\n",
    "    input_image = np.expand_dims(input_image, axis=0) / 255.0\n",
    "\n",
    "    # Передбачення за допомогою моделі\n",
    "    predictions = model.predict(input_image)\n",
    "    print(\"Predictions:\", predictions)\n",
    "\n",
    "    # Якщо логотип визначено на кадрі, вивести час\n",
    "    if predictions[0, class_names.index('apple')] > 0.5297:\n",
    "        current_frame = int(video_capture.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        current_time = current_frame / fps\n",
    "        print(f\"Logo detected at time: {current_time} seconds\")\n",
    "\n",
    "    # Відображення відео\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Вихід з циклу при натисканні клавіші 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Закриття відеоструму та вікна\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
